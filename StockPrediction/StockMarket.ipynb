{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n",
      "NVIDIA GeForce GTX 1050 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('Running on GPU')\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dir = './Stocks/CDNS_5y_12-23-21.csv'\n",
    "#s_dir = './Stocks/CDNS.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(s_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Open        High         Low       Close   Adj Close  \\\n",
      "1252  2021-12-15  176.699997  184.410004  176.250000  184.270004  184.270004   \n",
      "1253  2021-12-16  184.000000  184.009995  177.809998  179.619995  179.619995   \n",
      "1254  2021-12-17  177.080002  182.449997  177.080002  179.149994  179.149994   \n",
      "1255  2021-12-20  175.850006  178.619995  175.250000  177.320007  177.320007   \n",
      "1256  2021-12-21  179.580002  183.289993  176.580002  183.029999  183.029999   \n",
      "\n",
      "       Volume  \n",
      "1252  1813100  \n",
      "1253  1573400  \n",
      "1254  3447100  \n",
      "1255  1255100  \n",
      "1256   980600  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1257 entries, 0 to 1256\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1257 non-null   object \n",
      " 1   Open       1257 non-null   float64\n",
      " 2   High       1257 non-null   float64\n",
      " 3   Low        1257 non-null   float64\n",
      " 4   Close      1257 non-null   float64\n",
      " 5   Adj Close  1257 non-null   float64\n",
      " 6   Volume     1257 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 68.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.tail())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize datasets\n",
    "#scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "#closed_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00331492]\n",
      " [0.00405157]\n",
      " [0.00104359]\n",
      " ...\n",
      " [0.94493554]\n",
      " [0.93370173]\n",
      " [0.96875386]]\n"
     ]
    }
   ],
   "source": [
    "print(closed_data)\n",
    "np_data = closed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2af85ebe4c0>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(closed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split to train/test sets\n",
    "split = int(len(data)*0.7)\n",
    "\n",
    "np_train_set = np_data[:split]\n",
    "np_test_set = np_data[split:]\n",
    "#np_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN_dataset(data, seq_len):\n",
    "        x, y = [], []\n",
    "        total_len = len(data)\n",
    "        for i in range(total_len-seq_len):\n",
    "            x.append(data[i:i+seq_len])\n",
    "            y.append(data[seq_len+i:seq_len+i+30])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 90, 1)\n",
      "(789,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Temp/ipykernel_2132/7688748.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_train_x, np_train_y = np.array(np_train_x), np.array(np_train_y)\n",
      "C:\\Users\\brand\\AppData\\Local\\Temp/ipykernel_2132/7688748.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np_test_x, np_test_y = np.array(np_test_x), np.array(np_test_y)\n"
     ]
    }
   ],
   "source": [
    "sequence_l = 90\n",
    "\n",
    "#list of numpy array\n",
    "np_train_x, np_train_y = create_RNN_dataset(np_train_set, seq_len=sequence_l)\n",
    "#print(np_train_x)\n",
    "np_test_x, np_test_y = create_RNN_dataset(np_test_set, seq_len=sequence_l)\n",
    "\n",
    "np_train_x, np_train_y = np.array(np_train_x), np.array(np_train_y)\n",
    "np_test_x, np_test_y = np.array(np_test_x), np.array(np_test_y)\n",
    "print(np_train_x.shape)\n",
    "print(np_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([789, 90, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2132/1935248395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_train_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# convert list of numpy array to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_test_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_test_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "#convert from np arry to pytorch tensor\n",
    "train_x = torch.tensor(np.array(np_train_x)).float() # convert list of numpy array to numpy array\n",
    "print(train_x.size())\n",
    "train_y = torch.tensor(np.array(np_train_y)).squeeze().float()\n",
    "test_x = torch.tensor(np.array(np_test_x)).float()\n",
    "test_y = torch.tensor(np.array(np_test_y)).squeeze().float()\n",
    "#print(train_x.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2517],\n",
      "        [0.2766],\n",
      "        [0.2616],\n",
      "        [0.2425],\n",
      "        [0.2120],\n",
      "        [0.2314],\n",
      "        [0.2272],\n",
      "        [0.1947],\n",
      "        [0.2287],\n",
      "        [0.1804],\n",
      "        [0.2070],\n",
      "        [0.1786],\n",
      "        [0.1872],\n",
      "        [0.1833],\n",
      "        [0.1881],\n",
      "        [0.2340],\n",
      "        [0.2218],\n",
      "        [0.2561],\n",
      "        [0.2275],\n",
      "        [0.2559],\n",
      "        [0.2506],\n",
      "        [0.2457],\n",
      "        [0.2499],\n",
      "        [0.2376],\n",
      "        [0.2713],\n",
      "        [0.2691],\n",
      "        [0.2862],\n",
      "        [0.2850],\n",
      "        [0.2844],\n",
      "        [0.3138]])\n"
     ]
    }
   ],
   "source": [
    "print(train_x[800, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, i_size, h_size, n_layers, drop):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = n_layers\n",
    "        self.hidden_dim = h_size\n",
    "        self.lstm = nn.LSTM(input_size=i_size, hidden_size=h_size, num_layers=n_layers, batch_first=True, dropout=drop)\n",
    "        self.layer1 = nn.Linear(h_size, 1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device)\n",
    "        output, _ = self.lstm(x, (h0, c0))\n",
    "        #x = F.relu(self.layer1(x))\n",
    "        output = self.layer1(output[-1,:,:])\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 32, num_layers=2, batch_first=True)\n",
       "  (layer1): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = LSTM(1, 32, 2, 0)\n",
    "stock.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer = torch.optim.Adam(stock.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Function\n",
    "def train(model, batch_size, loss_f, optimizer, device):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    \n",
    "    total_batches = int(len(train_x[0])/batch_size)\n",
    "    \n",
    "    for batch_n in range (total_batches):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = train_x[:,batch_n*batch_size:(batch_n+1)*batch_size]\n",
    "        labels = train_y[batch_n*batch_size:(batch_n+1)*batch_size]\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_f(outputs, labels)\n",
    "        loss.backward()\n",
    "        losses.append(loss)\n",
    "        optimizer.step()\n",
    "    #print('Loss: ', losses)\n",
    "    #print('End of epoch loss:', round((sum(losses)/len(train_x)).item(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Function\n",
    "def test(model, batch_size, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_batches = int(len(test_x[0])/batch_size)\n",
    "    \n",
    "    for batch_n in range(total_batches):\n",
    "        inputs = test_x[:,batch_n*batch_size:(batch_n+1)*batch_size]\n",
    "        labels = test_y[batch_n*batch_size:(batch_n+1)*batch_size]\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        prediction = model(inputs)\n",
    "        #print('pred:', prediction.size())\n",
    "        print('pred:', prediction)\n",
    "        #correct += (prediction == labels).sum().item()\n",
    "        \n",
    "        #print('pred: ', prediction)\n",
    "        print('actual: ', labels)\n",
    "        #print('Expected: ', labels)\n",
    "    #print('End of epoch accuracy:', 100*correct/len(test_x), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  2\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  3\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  4\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  5\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  6\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  7\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  8\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  9\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  10\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  11\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  13\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  14\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  15\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  16\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  17\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  18\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  19\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  20\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  21\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  23\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  24\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  25\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  26\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  27\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  28\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  29\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  30\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  31\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  32\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  33\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  35\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  36\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  37\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  38\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  39\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  40\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  41\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  42\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  43\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  45\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  46\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  47\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  48\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  49\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  50\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  51\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  52\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  53\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  55\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  56\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  57\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  58\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  59\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  60\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  61\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  62\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  63\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  65\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  66\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  67\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  68\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  69\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  70\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  71\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  72\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  73\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  75\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  76\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  77\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  78\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  79\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  80\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  81\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  82\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  83\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  84\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  85\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  86\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  87\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  88\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  89\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  90\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  91\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  92\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  93\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  94\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  95\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  96\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  97\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  98\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  99\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n",
      "Epoch:  100\n",
      "pred: tensor([[-0.1411],\n",
      "        [-0.1343],\n",
      "        [-0.1291],\n",
      "        [-0.1249],\n",
      "        [-0.1218],\n",
      "        [-0.1195],\n",
      "        [-0.1179],\n",
      "        [-0.1167],\n",
      "        [-0.1160],\n",
      "        [-0.1155],\n",
      "        [-0.1151],\n",
      "        [-0.1149],\n",
      "        [-0.1147],\n",
      "        [-0.1146],\n",
      "        [-0.1145],\n",
      "        [-0.1144],\n",
      "        [-0.1144],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1142],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143],\n",
      "        [-0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "actual:  tensor([0.5236, 0.5114, 0.5032, 0.4909, 0.5037, 0.5122, 0.5082, 0.5175, 0.5152,\n",
      "        0.5114, 0.5282, 0.5239, 0.5283, 0.5282, 0.5368, 0.5165, 0.5257, 0.5260,\n",
      "        0.5449, 0.5640, 0.5085, 0.4952, 0.4618, 0.4857, 0.4727, 0.4683, 0.4789,\n",
      "        0.4912, 0.4747, 0.4661], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Train/Test Script\n",
    "for epoch in range(1,101):\n",
    "    print('Epoch: ', epoch)\n",
    "    train(stock, 30, loss_func, optimizer, device)\n",
    "    test(stock, 30, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "torch.save(stock.state_dict(), \"./StockModel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader\n",
    "stockModel = CNN()\n",
    "modelWeights = torch.load(\"./StockModel.pt\")\n",
    "stockModel.load_state_dict(modelWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.LSTM(input_size=30, hidden_size=20, num_layers=3, batch_first=True, dropout=0.2),\n",
    "    #nn.Linear(20,10),\n",
    "    #nn.Linear(10, 1)\n",
    "    #nn.Conv2d(1,16,7,stride=1,padding=2),\n",
    "    #nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "    #nn.Conv2d(16,32,7,stride=1,padding=1),\n",
    "    #nn.MaxPool2d(kernel_size=5, stride=3),\n",
    "    #nn.Conv2d(32,64,3,stride=1,padding=1),\n",
    "    #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0781e-01],\n",
      "         [ 3.6962e-01],\n",
      "         [-2.8077e-01],\n",
      "         [ 8.9057e-02],\n",
      "         [-1.1219e+00],\n",
      "         [-6.7937e-01],\n",
      "         [ 1.0048e+00],\n",
      "         [-9.8230e-01],\n",
      "         [-1.5039e+00],\n",
      "         [-3.7228e-01]],\n",
      "\n",
      "        [[ 1.1369e+00],\n",
      "         [ 9.5619e-01],\n",
      "         [ 7.6198e-04],\n",
      "         [ 1.7247e-01],\n",
      "         [ 2.9469e-01],\n",
      "         [ 1.8378e-01],\n",
      "         [ 9.6322e-02],\n",
      "         [-1.7440e-01],\n",
      "         [-1.4952e+00],\n",
      "         [ 2.1246e-02]],\n",
      "\n",
      "        [[-8.9841e-01],\n",
      "         [-4.7508e-01],\n",
      "         [-1.0861e+00],\n",
      "         [-2.0132e-01],\n",
      "         [-2.4031e+00],\n",
      "         [ 2.8254e-01],\n",
      "         [ 1.1632e+00],\n",
      "         [ 4.5747e-01],\n",
      "         [-5.5225e-01],\n",
      "         [-1.8980e-01]],\n",
      "\n",
      "        [[-1.2350e+00],\n",
      "         [ 4.2118e-01],\n",
      "         [ 6.5976e-01],\n",
      "         [-1.2103e+00],\n",
      "         [ 1.5877e+00],\n",
      "         [-1.7155e-02],\n",
      "         [-9.2476e-01],\n",
      "         [ 5.2618e-01],\n",
      "         [-1.1711e+00],\n",
      "         [ 1.0142e+00]],\n",
      "\n",
      "        [[ 1.5482e+00],\n",
      "         [ 1.6600e+00],\n",
      "         [ 5.0174e-01],\n",
      "         [-1.4887e+00],\n",
      "         [-4.6510e-01],\n",
      "         [ 2.1593e-01],\n",
      "         [ 1.0062e+00],\n",
      "         [-8.7382e-01],\n",
      "         [-9.9408e-02],\n",
      "         [-1.2254e+00]],\n",
      "\n",
      "        [[ 2.5581e-01],\n",
      "         [-1.9985e+00],\n",
      "         [ 2.1738e-01],\n",
      "         [ 8.4236e-01],\n",
      "         [-3.4859e-01],\n",
      "         [-8.6463e-01],\n",
      "         [ 5.0302e-01],\n",
      "         [ 2.3899e-02],\n",
      "         [ 1.0115e+00],\n",
      "         [-1.2376e-03]],\n",
      "\n",
      "        [[-4.3722e-01],\n",
      "         [-4.4708e-01],\n",
      "         [-1.2893e-02],\n",
      "         [-2.3579e+00],\n",
      "         [-1.4684e+00],\n",
      "         [-6.5224e-01],\n",
      "         [ 8.0839e-01],\n",
      "         [ 8.8992e-01],\n",
      "         [-1.4335e+00],\n",
      "         [-8.1062e-01]],\n",
      "\n",
      "        [[ 7.9672e-01],\n",
      "         [-2.6980e-01],\n",
      "         [-5.3310e-01],\n",
      "         [ 1.1385e+00],\n",
      "         [-1.2328e+00],\n",
      "         [-9.5407e-01],\n",
      "         [ 8.9417e-01],\n",
      "         [ 1.4008e+00],\n",
      "         [-4.1223e-01],\n",
      "         [ 2.7649e-01]],\n",
      "\n",
      "        [[ 6.2409e-01],\n",
      "         [ 2.5699e-01],\n",
      "         [ 3.4811e-01],\n",
      "         [ 2.8039e-01],\n",
      "         [ 4.4107e-01],\n",
      "         [-6.6044e-02],\n",
      "         [ 1.7935e-01],\n",
      "         [ 1.6413e-01],\n",
      "         [-1.6945e-01],\n",
      "         [ 1.5028e+00]],\n",
      "\n",
      "        [[-9.9768e-02],\n",
      "         [ 3.6271e-01],\n",
      "         [-9.3697e-01],\n",
      "         [-2.4071e-01],\n",
      "         [-7.9942e-01],\n",
      "         [ 1.2866e+00],\n",
      "         [-2.1287e-01],\n",
      "         [ 1.1398e+00],\n",
      "         [ 3.4237e+00],\n",
      "         [-1.3963e+00]],\n",
      "\n",
      "        [[ 1.3145e+00],\n",
      "         [-7.5743e-01],\n",
      "         [-1.4109e+00],\n",
      "         [ 2.7918e-02],\n",
      "         [ 9.9433e-01],\n",
      "         [ 1.1456e+00],\n",
      "         [ 7.0615e-01],\n",
      "         [ 2.1854e+00],\n",
      "         [ 4.9681e-01],\n",
      "         [ 1.0636e+00]],\n",
      "\n",
      "        [[-1.0554e-01],\n",
      "         [-1.3476e+00],\n",
      "         [-6.2621e-01],\n",
      "         [-3.0682e-01],\n",
      "         [ 2.4384e-01],\n",
      "         [-1.5915e+00],\n",
      "         [ 1.1677e+00],\n",
      "         [ 2.9357e-01],\n",
      "         [-2.3420e+00],\n",
      "         [-5.2477e-01]],\n",
      "\n",
      "        [[ 1.1795e+00],\n",
      "         [ 1.1402e+00],\n",
      "         [-9.5970e-01],\n",
      "         [ 6.6566e-01],\n",
      "         [ 9.3865e-01],\n",
      "         [ 9.9638e-01],\n",
      "         [-1.1611e+00],\n",
      "         [-4.9077e-01],\n",
      "         [-4.4960e-01],\n",
      "         [ 4.7150e-01]],\n",
      "\n",
      "        [[-1.3704e+00],\n",
      "         [-8.7601e-01],\n",
      "         [ 5.9896e-01],\n",
      "         [ 1.3871e-01],\n",
      "         [-1.3611e+00],\n",
      "         [-7.3226e-01],\n",
      "         [ 5.2425e-01],\n",
      "         [-1.4312e+00],\n",
      "         [-1.1336e+00],\n",
      "         [ 1.0199e-01]],\n",
      "\n",
      "        [[ 3.1899e+00],\n",
      "         [ 8.7859e-03],\n",
      "         [-1.7070e+00],\n",
      "         [ 1.2463e+00],\n",
      "         [-1.1746e-01],\n",
      "         [ 3.7929e-01],\n",
      "         [-1.4890e+00],\n",
      "         [ 1.9587e-02],\n",
      "         [-1.8941e+00],\n",
      "         [ 1.0931e+00]],\n",
      "\n",
      "        [[-2.4678e-01],\n",
      "         [ 1.9384e-01],\n",
      "         [ 4.9915e-01],\n",
      "         [ 6.3453e-01],\n",
      "         [-1.2172e-01],\n",
      "         [ 1.8340e-01],\n",
      "         [-1.4764e+00],\n",
      "         [ 7.5303e-01],\n",
      "         [-8.4871e-01],\n",
      "         [ 3.9539e-01]],\n",
      "\n",
      "        [[ 2.9154e-01],\n",
      "         [-7.6410e-01],\n",
      "         [ 1.0503e+00],\n",
      "         [ 2.2294e-01],\n",
      "         [-3.4896e-01],\n",
      "         [-4.7641e-02],\n",
      "         [-2.2666e+00],\n",
      "         [-1.5387e-01],\n",
      "         [-3.6333e-01],\n",
      "         [ 6.5236e-01]],\n",
      "\n",
      "        [[-5.7728e-02],\n",
      "         [-2.5532e-01],\n",
      "         [ 9.8081e-01],\n",
      "         [ 5.5425e-01],\n",
      "         [ 8.8329e-01],\n",
      "         [-2.0086e-01],\n",
      "         [-2.0507e-01],\n",
      "         [ 1.7299e-01],\n",
      "         [ 1.0814e+00],\n",
      "         [ 5.3417e-01]],\n",
      "\n",
      "        [[-6.6174e-01],\n",
      "         [-4.8210e-01],\n",
      "         [ 7.2911e-01],\n",
      "         [-4.4201e-01],\n",
      "         [ 2.3229e-01],\n",
      "         [ 1.2472e+00],\n",
      "         [-1.1354e+00],\n",
      "         [ 2.3226e-01],\n",
      "         [ 1.7602e+00],\n",
      "         [ 4.3922e-01]],\n",
      "\n",
      "        [[-1.8316e-01],\n",
      "         [-1.1088e+00],\n",
      "         [-1.9410e-01],\n",
      "         [ 2.2001e+00],\n",
      "         [ 3.1031e-01],\n",
      "         [-1.0059e+00],\n",
      "         [ 9.9346e-01],\n",
      "         [ 5.5161e-01],\n",
      "         [-2.3597e-01],\n",
      "         [-6.1596e-01]],\n",
      "\n",
      "        [[-4.7807e-01],\n",
      "         [-1.4156e-01],\n",
      "         [-5.4006e-01],\n",
      "         [ 1.8363e-01],\n",
      "         [ 5.1319e-01],\n",
      "         [ 1.0530e+00],\n",
      "         [ 7.6010e-01],\n",
      "         [-2.2088e-01],\n",
      "         [-2.3000e-01],\n",
      "         [ 2.4038e+00]],\n",
      "\n",
      "        [[-9.8549e-01],\n",
      "         [ 5.5129e-01],\n",
      "         [ 7.6447e-01],\n",
      "         [-7.4549e-01],\n",
      "         [-3.9065e-01],\n",
      "         [ 6.3234e-01],\n",
      "         [ 1.5154e-01],\n",
      "         [-1.1372e+00],\n",
      "         [ 7.7695e-01],\n",
      "         [ 8.1577e-01]],\n",
      "\n",
      "        [[-5.8131e-01],\n",
      "         [ 2.2461e-01],\n",
      "         [ 9.6698e-01],\n",
      "         [-1.8302e+00],\n",
      "         [ 7.6965e-01],\n",
      "         [-2.6211e-01],\n",
      "         [ 9.2002e-04],\n",
      "         [ 7.8211e-01],\n",
      "         [ 9.5461e-01],\n",
      "         [ 8.8489e-01]],\n",
      "\n",
      "        [[-5.2279e-01],\n",
      "         [ 8.7583e-01],\n",
      "         [-1.4347e+00],\n",
      "         [-9.3804e-01],\n",
      "         [ 1.1152e+00],\n",
      "         [-9.6477e-01],\n",
      "         [-1.1658e+00],\n",
      "         [-6.3403e-01],\n",
      "         [-2.1474e-01],\n",
      "         [ 1.8948e-01]],\n",
      "\n",
      "        [[-1.6723e+00],\n",
      "         [ 8.8917e-01],\n",
      "         [ 7.4791e-01],\n",
      "         [ 2.1443e+00],\n",
      "         [-1.3063e+00],\n",
      "         [ 1.2447e+00],\n",
      "         [ 3.7424e-01],\n",
      "         [ 3.0870e-01],\n",
      "         [ 9.5973e-01],\n",
      "         [ 1.3335e+00]],\n",
      "\n",
      "        [[-4.3476e-01],\n",
      "         [-5.6499e-01],\n",
      "         [ 9.4678e-01],\n",
      "         [-6.5076e-01],\n",
      "         [-4.6869e-03],\n",
      "         [ 1.7684e+00],\n",
      "         [ 8.5196e-01],\n",
      "         [ 1.0538e+00],\n",
      "         [ 1.3290e-01],\n",
      "         [-3.9322e-01]],\n",
      "\n",
      "        [[-1.2674e-01],\n",
      "         [-8.9777e-01],\n",
      "         [-6.7269e-01],\n",
      "         [ 9.8990e-02],\n",
      "         [ 8.2779e-01],\n",
      "         [-9.3390e-01],\n",
      "         [-4.3396e-01],\n",
      "         [ 6.2074e-01],\n",
      "         [ 4.9353e-02],\n",
      "         [-5.2057e-01]],\n",
      "\n",
      "        [[ 1.2698e-01],\n",
      "         [ 1.0843e+00],\n",
      "         [ 4.2815e-01],\n",
      "         [ 8.8496e-02],\n",
      "         [ 1.3433e+00],\n",
      "         [ 3.3329e-01],\n",
      "         [ 3.4214e-01],\n",
      "         [ 3.9197e-01],\n",
      "         [-1.5674e-01],\n",
      "         [-1.6670e+00]],\n",
      "\n",
      "        [[-5.1304e-02],\n",
      "         [ 3.3081e-01],\n",
      "         [-1.3076e+00],\n",
      "         [ 7.2598e-01],\n",
      "         [-6.0393e-01],\n",
      "         [-1.2092e-01],\n",
      "         [-1.1760e+00],\n",
      "         [-1.3897e-01],\n",
      "         [-5.3552e-01],\n",
      "         [ 3.9457e-01]],\n",
      "\n",
      "        [[-3.2965e-01],\n",
      "         [-5.4320e-02],\n",
      "         [ 9.7048e-01],\n",
      "         [ 2.2232e+00],\n",
      "         [ 3.8587e-02],\n",
      "         [ 1.0494e-01],\n",
      "         [ 4.8197e-01],\n",
      "         [-1.0208e+00],\n",
      "         [ 2.6857e+00],\n",
      "         [ 1.6716e-01]]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(30,10,1)\n",
    "print(inputs)\n",
    "#output, (h_0,c_0) = m(inputs)\n",
    "#output.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
